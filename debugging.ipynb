{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import ImageFile,Image\n",
    "import  glob\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model, image):\n",
    "    model.eval()\n",
    "    img = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        outputs=torch.softmax(outputs, dim=1, dtype=float)\n",
    "        print(torch.sum(outputs))\n",
    "        print(outputs)\n",
    "        print(outputs.shape)\n",
    "\n",
    "        x, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        print(x)\n",
    "        print(preds)\n",
    "    return class_names[preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(loader, image):\n",
    "    image = loader(image).float()\n",
    "    image = torch.tensor(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        #transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Resize((64, 64)),\n",
    "        transforms.Resize((224, 224)),\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = 'arranged_data_final'\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                           data_transforms[x])\n",
    "#                   for x in ['train', 'val']}\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=416,\n",
    "#                                              shuffle=True, num_workers=16)\n",
    "#               for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# class_names = image_datasets['train'].classes\n",
    "# print(len(class_names))\n",
    "\n",
    "# with open('labels.txt', 'w') as filehandle:\n",
    "#     for listitem in class_names:\n",
    "#         filehandle.write('%s\\n' % listitem)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# model_ft.load_state_dict(torch.load('./weights/resnet50_f.pth'))\n",
    "\n",
    "# classes=glob.glob('./arranged_data_final/val/*')\n",
    "# all_images=[glob.glob(classes[i]+'/*') for i in range(len(classes)) ]\n",
    "# merged_images=list(itertools.chain.from_iterable(all_images))\n",
    "\n",
    "# import time\n",
    "# start_time=time.time()\n",
    "# count=0\n",
    "# for j in merged_images:\n",
    "#     print(j)\n",
    "#     image=Image.open(j)\n",
    "#     image=image_loader(data_transforms['val'], image)\n",
    "#     pred_name=predictions(model_ft, image)\n",
    "#     count=count+1\n",
    "\n",
    "\n",
    "# end_time=time.time()\n",
    "\n",
    "# print('Total time=', end_time-start_time)\n",
    "# print('Total images processed=', count)\n",
    "# print('Frames Per Seconds with Pytorch Model =', count/(end_time-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, device='cuda:0', dtype=torch.float64)\n",
      "tensor([[4.6286e-07, 1.5798e-06, 1.5578e-07, 1.0131e-07, 2.2478e-07, 3.0348e-07,\n",
      "         6.0940e-08, 3.6354e-06, 3.3757e-06, 4.3724e-07, 5.6528e-07, 2.7677e-07,\n",
      "         6.7435e-07, 4.3474e-07, 8.3383e-08, 1.4044e-05, 2.1738e-06, 3.2358e-06,\n",
      "         3.3476e-06, 1.2653e-06, 7.6646e-07, 3.6587e-06, 2.0857e-07, 2.7986e-06,\n",
      "         4.0355e-06, 2.7007e-06, 2.1486e-06, 4.3949e-07, 3.0497e-06, 8.5125e-07,\n",
      "         1.5368e-05, 6.5271e-07, 5.8573e-06, 3.5700e-06, 2.7601e-06, 2.0952e-06,\n",
      "         1.0661e-06, 8.2749e-07, 1.2434e-06, 1.1334e-06, 5.4278e-07, 6.1641e-07,\n",
      "         3.0090e-07, 2.0922e-06, 1.6716e-06, 4.2435e-06, 4.8513e-07, 8.7027e-07,\n",
      "         3.1927e-07, 7.6629e-07, 2.1055e-06, 6.1632e-08, 3.3620e-06, 2.8051e-06,\n",
      "         8.2211e-05, 4.8806e-07, 3.9070e-06, 3.4657e-06, 4.8231e-06, 1.9639e-06,\n",
      "         4.4633e-06, 6.9367e-07, 2.7887e-07, 1.3978e-06, 2.9895e-07, 1.5200e-06,\n",
      "         1.1542e-06, 1.2409e-06, 7.5512e-07, 5.7132e-07, 3.5269e-07, 8.0173e-06,\n",
      "         2.0838e-07, 3.8029e-07, 6.5174e-07, 2.3532e-06, 1.5156e-06, 1.4405e-06,\n",
      "         3.3495e-07, 2.1938e-06, 3.9699e-06, 1.6957e-06, 3.2161e-06, 1.7523e-06,\n",
      "         3.8294e-07, 3.3236e-06, 1.2839e-06, 6.2182e-07, 1.3872e-07, 2.4201e-06,\n",
      "         1.2360e-06, 1.7261e-06, 3.7694e-07, 2.1139e-06, 5.4311e-07, 8.0875e-07,\n",
      "         3.9623e-07, 1.0347e-07, 4.2832e-07, 8.7689e-08, 4.2190e-07, 3.5328e-07,\n",
      "         1.5207e-07, 2.2497e-07, 8.8196e-08, 8.6104e-08, 2.1945e-07, 2.2832e-07,\n",
      "         1.7894e-07, 8.8269e-08, 1.7579e-07, 1.3778e-07, 2.4151e-06, 2.2519e-06,\n",
      "         3.3832e-06, 9.1546e-08, 1.4928e-06, 1.3588e-07, 4.9404e-07, 5.4534e-07,\n",
      "         1.0409e-07, 3.8874e-07, 5.9741e-07, 4.8646e-07, 2.4304e-06, 2.9428e-06,\n",
      "         1.6571e-06, 3.7831e-06, 1.0536e-06, 3.9488e-07, 2.3328e-07, 3.9910e-08,\n",
      "         1.4888e-07, 3.5830e-07, 8.1339e-08, 8.4491e-07, 3.2663e-08, 9.1250e-08,\n",
      "         2.5565e-07, 3.7463e-07, 1.2180e-07, 4.3561e-07, 2.2878e-07, 3.8670e-07,\n",
      "         1.1451e-07, 6.7047e-07, 3.7055e-07, 1.5227e-07, 2.6446e-08, 8.0885e-08,\n",
      "         4.5691e-07, 8.5028e-06, 9.2156e-06, 7.2766e-07, 4.8507e-06, 1.6706e-06,\n",
      "         9.9907e-07, 2.2458e-06, 3.0775e-06, 2.1381e-06, 3.4536e-08, 4.5921e-07,\n",
      "         1.2386e-07, 7.1508e-07, 2.1066e-06, 2.0828e-07, 5.3761e-07, 2.3767e-07,\n",
      "         4.7848e-07, 1.1850e-07, 3.8348e-07, 4.7554e-06, 7.1025e-07, 7.9619e-07,\n",
      "         9.1111e-07, 2.5801e-07, 6.9766e-07, 5.3074e-07, 4.9869e-07, 1.0427e-06,\n",
      "         5.0795e-07, 3.0536e-07, 1.5790e-06, 8.4063e-06, 9.7794e-07, 4.2909e-06,\n",
      "         4.7122e-06, 4.8993e-06, 9.7116e-07, 4.1525e-07, 3.7647e-06, 1.1511e-06,\n",
      "         5.8682e-07, 6.4184e-07, 8.1893e-07, 1.2625e-05, 2.2320e-06, 1.6879e-06,\n",
      "         3.6331e-06, 6.1884e-07, 4.2404e-06, 5.6813e-07, 4.5189e-06, 1.4550e-06,\n",
      "         1.3718e-06, 6.1711e-07, 2.8499e-07, 2.6394e-06, 1.1161e-06, 1.6237e-07,\n",
      "         3.4353e-07, 8.6052e-07, 1.5708e-06, 5.8604e-07, 7.5317e-07, 1.0061e-06,\n",
      "         5.0478e-07, 4.3967e-07, 9.5256e-07, 3.2178e-07, 3.2046e-07, 3.5738e-08,\n",
      "         2.5452e-06, 5.2173e-07, 4.2891e-07, 2.0710e-06, 5.3603e-07, 1.1602e-06,\n",
      "         4.4648e-07, 4.3812e-07, 2.9192e-07, 1.9790e-06, 9.6858e-06, 3.6416e-07,\n",
      "         9.9633e-07, 2.6831e-06, 1.8045e-06, 1.5418e-06, 1.8916e-06, 1.5803e-06,\n",
      "         1.0166e-05, 1.5202e-06, 2.6985e-06, 5.0014e-06, 2.7927e-07, 1.6402e-07,\n",
      "         4.0819e-06, 1.5647e-06, 5.5316e-06, 3.8622e-07, 7.4038e-07, 7.1614e-07,\n",
      "         1.6297e-06, 1.0157e-06, 3.9767e-05, 1.1269e-06, 2.1799e-07, 2.1638e-06,\n",
      "         1.7609e-06, 2.7040e-06, 2.3101e-07, 2.5197e-07, 1.2784e-05, 6.1964e-07,\n",
      "         4.3788e-07, 1.3039e-06, 3.1596e-07, 4.0448e-07, 4.1287e-07, 1.2249e-06,\n",
      "         8.7429e-07, 2.3085e-07, 5.3496e-07, 2.9905e-06, 1.8102e-07, 1.4877e-07,\n",
      "         5.6896e-08, 7.6721e-08, 3.3810e-08, 1.3395e-07, 8.8394e-07, 2.6470e-07,\n",
      "         3.7252e-07, 1.8035e-07, 4.4823e-07, 2.1553e-06, 6.5583e-07, 4.4849e-07,\n",
      "         4.5858e-07, 4.9701e-07, 4.8044e-07, 4.3147e-07, 4.9053e-07, 4.5316e-07,\n",
      "         2.1861e-08, 3.4056e-08, 2.0259e-07, 1.0867e-07, 3.2763e-07, 9.8371e-07,\n",
      "         1.2049e-07, 7.6618e-08, 1.3805e-06, 3.9182e-07, 1.5357e-07, 1.2540e-06,\n",
      "         2.4216e-06, 1.2264e-07, 2.2929e-07, 3.6583e-07, 1.5475e-06, 3.5634e-07,\n",
      "         3.5601e-07, 1.9108e-06, 1.0536e-06, 6.2805e-07, 1.0033e-06, 2.0783e-08,\n",
      "         2.3375e-07, 1.3912e-07, 2.6449e-07, 4.3925e-07, 1.3846e-07, 3.4542e-07,\n",
      "         6.5072e-08, 3.4816e-08, 1.6236e-07, 2.1226e-06, 2.2785e-06, 3.5900e-06,\n",
      "         1.3535e-07, 4.2112e-07, 1.2556e-07, 5.3710e-07, 1.5426e-08, 3.6126e-06,\n",
      "         8.3116e-07, 8.3608e-08, 4.9008e-07, 7.3869e-08, 2.4961e-07, 1.1299e-07,\n",
      "         1.5336e-08, 1.9872e-08, 4.5693e-07, 4.8615e-07, 2.8348e-08, 6.6122e-08,\n",
      "         1.1782e-06, 4.8782e-07, 1.0957e-07, 4.4375e-08, 4.0898e-07, 1.2876e-07,\n",
      "         1.7815e-07, 8.9822e-07, 2.7772e-06, 5.4067e-07, 1.2406e-05, 8.8441e-06,\n",
      "         1.5149e-06, 3.0616e-07, 2.9414e-07, 2.6931e-07, 2.2522e-07, 2.0966e-07,\n",
      "         4.5766e-08, 3.5895e-07, 1.6065e-06, 9.5298e-07, 8.0579e-07, 1.4261e-07,\n",
      "         2.2688e-08, 5.6874e-07, 2.8887e-07, 1.4326e-07, 1.8850e-07, 2.4977e-06,\n",
      "         9.8864e-08, 1.0258e-07, 5.6777e-07, 3.2918e-07, 7.2128e-07, 1.6798e-07,\n",
      "         1.1808e-06, 1.3376e-07, 1.7459e-08, 1.0951e-07, 1.1841e-07, 4.9996e-07,\n",
      "         1.8981e-07, 6.8739e-07, 8.8803e-08, 6.2117e-08, 3.6347e-07, 2.6879e-07,\n",
      "         3.3622e-07, 4.2194e-06, 4.0890e-07, 3.0727e-06, 5.1217e-06, 3.2823e-06,\n",
      "         1.4053e-06, 1.4643e-07, 2.4989e-07, 6.9629e-07, 9.3110e-08, 2.9155e-06,\n",
      "         2.9687e-06, 5.8087e-04, 1.4216e-07, 6.3479e-07, 8.1983e-07, 1.4316e-05,\n",
      "         7.6957e-06, 3.5029e-07, 1.6674e-06, 1.3062e-06, 1.7689e-05, 1.4278e-05,\n",
      "         1.3844e-06, 1.2500e-06, 4.7172e-06, 2.8519e-07, 3.5394e-06, 1.7599e-07,\n",
      "         2.3771e-05, 8.6663e-07, 1.3126e-07, 1.5543e-05, 5.9851e-07, 5.0676e-08,\n",
      "         1.6083e-07, 6.3802e-06, 3.8961e-07, 2.5842e-06, 5.1657e-06, 1.9608e-06,\n",
      "         2.7091e-06, 8.2475e-06, 1.8475e-05, 8.4790e-06, 3.9087e-06, 1.0156e-07,\n",
      "         2.5021e-07, 4.9994e-06, 2.5902e-07, 3.2995e-04, 1.0190e-06, 7.9631e-07,\n",
      "         1.2548e-06, 9.9029e-07, 1.0773e-06, 4.2595e-07, 4.9124e-07, 1.3618e-05,\n",
      "         6.5864e-06, 1.9290e-05, 9.9655e-07, 2.6285e-06, 2.6089e-07, 3.4085e-07,\n",
      "         8.5928e-08, 2.0626e-07, 3.2884e-05, 1.3426e-05, 3.5724e-07, 9.1483e-08,\n",
      "         8.8250e-06, 2.7846e-06, 1.8966e-06, 5.0278e-06, 8.4961e-08, 1.4605e-05,\n",
      "         9.5580e-07, 5.8449e-04, 4.1907e-07, 8.5719e-07, 2.1190e-06, 6.7685e-05,\n",
      "         1.6150e-06, 3.4859e-05, 8.6598e-05, 1.6526e-06, 5.4912e-08, 6.0207e-05,\n",
      "         8.7616e-08, 1.5900e-03, 3.9489e-05, 4.2522e-07, 6.8365e-07, 1.7637e-06,\n",
      "         7.7723e-07, 7.3268e-08, 2.4799e-06, 1.1051e-07, 2.5377e-07, 9.9729e-07,\n",
      "         5.6537e-07, 4.0311e-07, 9.6083e-09, 1.3471e-06, 4.9183e-07, 1.2918e-06,\n",
      "         1.0506e-05, 6.4433e-06, 1.1136e-06, 1.5779e-03, 4.7325e-06, 1.4552e-07,\n",
      "         6.3842e-07, 1.1288e-05, 6.0637e-06, 3.7869e-06, 6.0628e-07, 3.0683e-05,\n",
      "         1.4362e-08, 1.7429e-06, 2.2596e-05, 4.5863e-07, 2.7734e-08, 6.4718e-06,\n",
      "         1.1645e-06, 9.6857e-07, 2.7484e-07, 1.3425e-07, 5.8677e-07, 5.8132e-07,\n",
      "         8.0354e-05, 4.8272e-07, 2.0046e-04, 4.6518e-03, 6.5936e-08, 4.5955e-07,\n",
      "         2.4773e-06, 3.3149e-05, 2.9500e-07, 1.6083e-07, 5.4436e-07, 3.7663e-07,\n",
      "         2.1812e-07, 2.3222e-06, 3.6695e-06, 2.9119e-05, 6.4128e-07, 1.6182e-06,\n",
      "         1.6856e-06, 1.1583e-06, 1.3613e-06, 4.6280e-07, 7.2305e-06, 2.7812e-06,\n",
      "         9.5579e-06, 1.3395e-07, 3.0599e-07, 3.4188e-06, 1.0705e-07, 1.5482e-06,\n",
      "         2.2564e-06, 4.1681e-08, 3.4777e-06, 1.2687e-06, 7.2584e-07, 4.1524e-06,\n",
      "         2.4878e-08, 1.9888e-07, 4.1331e-07, 5.1261e-07, 2.6616e-06, 1.3944e-06,\n",
      "         2.7202e-05, 3.0258e-06, 2.0306e-06, 6.6779e-07, 6.1364e-06, 1.2150e-06,\n",
      "         4.0904e-08, 1.7772e-06, 4.6197e-06, 7.8349e-07, 6.9413e-07, 4.6934e-06,\n",
      "         1.7203e-07, 5.2914e-07, 4.4100e-07, 2.6971e-05, 1.8620e-05, 2.8386e-06,\n",
      "         2.7336e-07, 1.7465e-06, 5.5713e-05, 5.9002e-07, 1.0690e-05, 3.6952e-05,\n",
      "         5.8350e-07, 3.0079e-07, 1.9164e-06, 3.9059e-06, 4.8945e-06, 4.4222e-06,\n",
      "         2.0689e-06, 1.3536e-07, 1.2396e-06, 1.5961e-07, 1.3012e-06, 4.8677e-05,\n",
      "         9.7550e-07, 1.4146e-07, 4.6409e-06, 7.0616e-05, 5.7279e-06, 6.1874e-07,\n",
      "         3.3420e-07, 5.3226e-05, 5.1403e-06, 2.3602e-06, 8.0061e-06, 5.3328e-06,\n",
      "         5.9958e-07, 1.9815e-07, 1.6979e-06, 2.4930e-06, 1.2707e-02, 6.2413e-06,\n",
      "         2.9744e-07, 1.3896e-07, 4.6871e-04, 1.4350e-05, 1.0974e-07, 2.7907e-05,\n",
      "         1.3008e-06, 2.7892e-06, 3.7082e-05, 5.2756e-04, 8.2726e-07, 1.6344e-03,\n",
      "         1.3414e-06, 3.7509e-06, 2.3869e-06, 7.5232e-07, 1.5207e-08, 5.4843e-07,\n",
      "         1.6885e-07, 1.3748e-06, 3.5675e-06, 1.2058e-07, 2.8201e-07, 1.5243e-06,\n",
      "         1.4714e-06, 1.2055e-07, 2.0796e-05, 1.8616e-05, 8.2206e-05, 7.6373e-07,\n",
      "         4.3275e-06, 1.8563e-06, 9.1915e-07, 1.4376e-06, 3.5738e-07, 7.6520e-07,\n",
      "         1.3553e-06, 1.4256e-05, 1.5123e-05, 2.6387e-07, 6.6978e-05, 1.2135e-06,\n",
      "         6.2985e-07, 1.9263e-06, 8.2942e-08, 3.9235e-08, 1.2382e-06, 1.6590e-05,\n",
      "         5.9209e-07, 3.3920e-06, 1.0609e-06, 2.0096e-07, 4.3345e-06, 8.6370e-07,\n",
      "         5.9901e-06, 1.9819e-06, 3.2535e-06, 7.3944e-06, 4.3496e-07, 6.1364e-07,\n",
      "         1.0001e-06, 7.7386e-05, 4.3218e-05, 4.0690e-08, 8.0297e-05, 3.6062e-07,\n",
      "         2.1998e-07, 5.7948e-06, 4.4313e-06, 2.5745e-07, 4.9284e-08, 1.9339e-05,\n",
      "         9.4191e-07, 3.4066e-06, 2.5603e-07, 1.0580e-06, 5.1063e-07, 5.6068e-07,\n",
      "         5.9996e-07, 5.0814e-07, 2.2074e-05, 6.5054e-06, 2.3775e-07, 3.0291e-05,\n",
      "         4.6131e-07, 8.3678e-07, 5.9292e-06, 4.8920e-05, 2.8448e-06, 5.7604e-07,\n",
      "         2.2141e-06, 1.4767e-06, 1.4381e-06, 2.6586e-05, 1.2957e-07, 5.0330e-06,\n",
      "         4.1693e-06, 4.7318e-08, 1.3143e-05, 4.4349e-06, 9.4060e-08, 5.3714e-07,\n",
      "         1.2336e-06, 5.6238e-07, 2.7033e-06, 4.2286e-08, 2.7418e-07, 8.2300e-07,\n",
      "         5.1614e-02, 9.5273e-06, 4.8825e-06, 5.0561e-07, 1.6275e-06, 4.1116e-06,\n",
      "         4.3121e-07, 2.8101e-07, 6.8226e-06, 9.0916e-08, 2.0104e-06, 3.4986e-06,\n",
      "         8.8265e-06, 5.0477e-04, 4.0682e-06, 1.0194e-06, 2.4940e-06, 1.0729e-05,\n",
      "         2.2731e-07, 1.7414e-05, 6.3187e-07, 3.2325e-06, 3.8564e-04, 6.5179e-07,\n",
      "         1.1161e-06, 2.1920e-06, 2.2204e-05, 9.1540e-01, 1.3190e-06, 4.8950e-05,\n",
      "         7.1328e-07, 5.8566e-05, 2.7491e-05, 1.9995e-08, 9.8823e-06, 1.2365e-06,\n",
      "         2.3026e-06, 3.8357e-06, 1.9309e-06, 1.7086e-04, 1.1053e-06, 2.9108e-06,\n",
      "         1.7015e-06, 6.7833e-07, 7.4449e-07, 2.3398e-07, 1.9743e-06, 9.4143e-07,\n",
      "         1.5853e-07, 2.6146e-06, 3.9770e-05, 1.1575e-04, 9.0582e-06, 1.4494e-05,\n",
      "         8.1152e-06, 8.6490e-07, 6.4900e-07, 2.2382e-06, 1.8426e-07, 2.5493e-07,\n",
      "         5.1538e-08, 1.1009e-05, 2.2142e-07, 6.2738e-07, 7.0622e-06, 1.2200e-06,\n",
      "         3.6131e-06, 8.8632e-07, 2.0016e-06, 2.1563e-06, 1.7752e-07, 1.1576e-06,\n",
      "         9.5246e-07, 2.2188e-06, 1.4894e-07, 5.4494e-07, 1.4732e-05, 1.4835e-06,\n",
      "         1.0672e-05, 1.3376e-06, 1.3274e-06, 6.4781e-07, 5.9893e-07, 5.4591e-07,\n",
      "         3.4080e-07, 7.1569e-06, 1.2609e-05, 6.0180e-06, 8.1761e-06, 2.0725e-07,\n",
      "         2.4732e-07, 1.0789e-05, 5.8966e-06, 1.1576e-07, 1.7738e-03, 2.6529e-06,\n",
      "         3.1332e-06, 3.7226e-06, 3.8339e-07, 1.7043e-07, 8.2482e-08, 5.7796e-08,\n",
      "         7.0868e-06, 9.2374e-07, 2.7335e-04, 9.9265e-05, 1.0494e-06, 4.5523e-07,\n",
      "         4.3576e-07, 1.3284e-06, 1.0054e-06, 1.9979e-07, 3.0488e-05, 3.5688e-06,\n",
      "         1.5279e-07, 1.0148e-05, 5.9467e-05, 3.7785e-06, 2.9769e-06, 1.0101e-04,\n",
      "         5.0522e-06, 1.7018e-07, 6.0548e-07, 2.4852e-06, 2.6994e-07, 3.8535e-08,\n",
      "         2.5512e-07, 1.6083e-05, 2.4902e-06, 9.0440e-08, 3.3644e-05, 1.9988e-07,\n",
      "         4.5575e-06, 1.9132e-06, 2.1379e-06, 2.5789e-06, 5.1116e-07, 1.2167e-05,\n",
      "         1.7397e-07, 7.5979e-08, 7.8573e-04, 2.9856e-07, 8.1649e-07, 9.7993e-07,\n",
      "         6.9358e-06, 1.6930e-06, 6.5583e-06, 2.3621e-06, 4.5194e-07, 4.8565e-07,\n",
      "         3.6394e-07, 4.4743e-07, 1.8918e-07, 2.7693e-07, 9.4966e-07, 7.0095e-08,\n",
      "         2.9057e-07, 6.0695e-07, 4.8909e-07, 2.4812e-06, 8.0947e-06, 1.7913e-06,\n",
      "         2.8477e-07, 1.0176e-06, 3.5473e-07, 7.2734e-06, 1.0285e-05, 2.6260e-06,\n",
      "         2.0815e-07, 7.0554e-06, 8.9511e-05, 2.9333e-06, 2.7502e-06, 9.4677e-07,\n",
      "         5.3961e-06, 5.8938e-06, 9.9643e-07, 7.0332e-07, 3.2804e-07, 7.1053e-07,\n",
      "         7.0491e-06, 1.2017e-07, 3.9046e-08, 2.2832e-07, 7.5449e-06, 4.6657e-07,\n",
      "         8.5026e-07, 7.1104e-07, 1.8106e-06, 3.8962e-06, 3.3993e-07, 5.2304e-07,\n",
      "         1.3356e-06, 1.6317e-06, 2.3444e-06, 3.2493e-07, 3.7598e-07, 3.4652e-06,\n",
      "         2.3848e-06, 5.8268e-07, 1.3146e-06, 2.6309e-07, 7.9209e-06, 9.5490e-07,\n",
      "         2.4197e-07, 1.1129e-06, 1.3764e-06, 6.3274e-07, 4.5262e-07, 6.8746e-07,\n",
      "         1.0452e-06, 1.2296e-07, 9.5248e-07, 3.7174e-07, 4.6846e-07, 4.9622e-07,\n",
      "         1.8724e-06, 4.0617e-07, 4.4679e-07, 7.2239e-07, 4.6324e-07, 2.4595e-07,\n",
      "         2.0832e-07, 1.2779e-07, 3.0768e-07, 4.4002e-07, 1.9035e-06, 7.6204e-07,\n",
      "         2.9289e-06, 1.3013e-06, 9.6760e-07, 4.4567e-07, 6.1361e-07, 7.2082e-06,\n",
      "         9.7926e-06, 3.4509e-06, 6.1538e-06, 5.9375e-06, 5.0213e-06, 5.4112e-05,\n",
      "         9.7038e-07, 9.7962e-08, 8.1872e-07, 1.3672e-06, 1.6628e-07, 6.4289e-07,\n",
      "         4.2036e-07, 2.7288e-07, 7.9714e-07, 7.0430e-06, 5.8215e-06, 1.9613e-06,\n",
      "         7.3539e-07, 1.6451e-07, 2.6527e-07, 1.4341e-06, 4.3520e-06, 4.7759e-07,\n",
      "         1.6191e-06, 4.5604e-07, 1.5155e-07, 2.4881e-07, 6.0200e-07, 3.4601e-06,\n",
      "         6.7807e-07, 2.6650e-07, 3.6609e-06, 3.7644e-07]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "torch.Size([1, 1000])\n",
      "tensor([0.9154], device='cuda:0', dtype=torch.float64)\n",
      "tensor([759], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamerx/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e77da0c1074a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpred_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-deacf3d70b87>\u001b[0m in \u001b[0;36mpredictions\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "j='/usr/src/tensorrt/data/resnet50/reflex_camera.jpeg'\n",
    "# j='/usr/src/tensorrt/data/resnet50/binoculars.jpeg'\n",
    "\n",
    "image=Image.open(j)\n",
    "image=image_loader(data_transforms['val'], image)\n",
    "pred_name=predictions(model_ft, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
